import os
import pandas as pd
from flask import Flask, request, jsonify
from flask_cors import CORS
from fuzzywuzzy import fuzz, process
import tableauserverclient as TSC
import pantab as pt
from tableauhyperapi import TableName
import gc  # –î–ª—è –æ—á–∏—â–µ–Ω–Ω—è –ø–∞–º'—è—Ç—ñ

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –°–µ—Ä–≤–µ—Ä–∞ ---
app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "https://my-diploma-project.vercel.app"}})

# --- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –ú–æ–¥–µ–ª—å –î–∞–Ω–∏—Ö ---
STANDARD_COLUMNS = {
    'Transaction_Date': ['–¥–∞—Ç–∞', '–¥–∞—Ç–∞ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è', 'date', 'order_date', 'time', 'datetime'],
    'Transaction_ID': ['id', '–Ω–æ–º–µ—Ä –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è', 'transaction id', 'order id', '–Ω–æ–º–µ—Ä —á–µ–∫–∞', 'ticket_number', 'ticket',
                       'receipt_id'],
    'Product_Category': ['–∫–∞—Ç–µ–≥–æ—Ä—ñ—è', 'category', 'product category', '–∫–∞—Ç–µ–≥–æ—Ä—ñ—è —Ç–æ–≤–∞—Ä—É', 'article', 'item_group'],
    'Quantity': ['–∫—ñ–ª—å–∫—ñ—Å—Ç—å', 'quantity', 'qty', '–∫—ñ–ª-—Ç—å', 'pieces'],
    'Price_Per_Unit': ['—Ü—ñ–Ω–∞', 'price', '—Ü—ñ–Ω–∞ –∑–∞ –æ–¥', 'unit_price', 'amount', 'Price per Unit'],
    'Cost_Per_Unit': ['—Å–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å', 'cost', 'cost per unit'],
    'Client_Region': ['—Ä–µ–≥—ñ–æ–Ω', '–º—ñ—Å—Ç–æ', 'region', 'city', 'client region', '—Ä–µ–≥—ñ–æ–Ω –¥–æ—Å—Ç–∞–≤–∫–∏'],
}


# –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ float64 –¥–ª—è Quantity, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º –∑ –ø–∞–º'—è—Ç—Ç—é —Ç–∞ —Ç–∏–ø–∞–º–∏
TABLEAU_SCHEMA = {
    'Transaction_Date': 'datetime64[ns]',
    'Transaction_ID': 'string',  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 'string' –∑–∞–º—ñ—Å—Ç—å 'object'
    'Product_Category': 'string',  # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ 'string'
    'Quantity': 'float64',  # float64 –ª–µ–≥—à–µ –¥–ª—è pantab
    'Price_Per_Unit': 'float64',
    'Cost_Per_Unit': 'float64',
    'Client_Region': 'string',
    'Revenue': 'float64',
    'Profit': 'float64'
}

# --- –°–õ–û–í–ù–ò–ö –ú–ê–†–ñ–Ü ---
MARGIN_FALLBACKS_BY_CATEGORY = {
    'Electronics': 0.20, 'Apparel': 0.40, 'Home Goods': 0.35,
    'Food': 0.15, 'Automotive': 0.10, '–ï–ª–µ–∫—Ç—Ä–æ–Ω—ñ–∫–∞': 0.20,
    '–û–¥—è–≥': 0.40, '–¢–æ–≤–∞—Ä–∏ –¥–ª—è –¥–æ–º—É': 0.35, '–ü—Ä–æ–¥—É–∫—Ç–∏': 0.15,
    'default': 0.30
}

CLEAN_CATEGORIES = list(MARGIN_FALLBACKS_BY_CATEGORY.keys())


def get_smart_category(dirty_category):
    if pd.isna(dirty_category) or str(dirty_category).strip() == "":
        return 'default'

    # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è: —è–∫—â–æ –≤–∂–µ —î —Ç–æ—á–Ω–∏–π –∑–±—ñ–≥
    dirty_str = str(dirty_category)
    if dirty_str in MARGIN_FALLBACKS_BY_CATEGORY:
        return dirty_str

    best_match, score = process.extractOne(dirty_str.lower(), CLEAN_CATEGORIES, scorer=fuzz.token_set_ratio)
    if score > 60:
        return best_match
    else:
        return 'default'


def publish_to_tableau_cloud(file_path):
    try:
        server_url = os.environ['TABLEAU_SERVER_URL']
        site_id = os.environ['TABLEAU_SITE_ID']
        pat_name = os.environ['TABLEAU_PAT_NAME']
        pat_secret = os.environ['TABLEAU_PAT_SECRET']
        datasource_name_to_update = 'live_sales_data'

        print(f"–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ {server_url}...")
        tableau_auth = TSC.PersonalAccessTokenAuth(pat_name, pat_secret, site_id=site_id)
        server = TSC.Server(server_url, use_server_version=True)

        with server.auth.sign_in(tableau_auth):
            print("–í—Ö—ñ–¥ –≤–∏–∫–æ–Ω–∞–Ω–æ.")
            req_option = TSC.RequestOptions()
            req_option.filter.add(TSC.Filter(TSC.RequestOptions.Field.Name, TSC.RequestOptions.Operator.Equals,
                                             datasource_name_to_update))
            all_datasources, _ = server.datasources.get(req_option)

            if not all_datasources:
                return f"–ü–æ–º–∏–ª–∫–∞: –î–∂–µ—Ä–µ–ª–æ '{datasource_name_to_update}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."

            datasource_to_update = all_datasources[0]
            print(f"–ü—É–±–ª—ñ–∫—É—é (ID: {datasource_to_update.id})...")
            server.datasources.publish(datasource_to_update, file_path, 'Overwrite')
            print(f"–£—Å–ø—ñ—Ö.")
            return None

    except TSC.ServerResponseError as e:
        return f"–ü–æ–º–∏–ª–∫–∞ Tableau: {e.summary}"
    except Exception as e:
        return f"–ü–æ–º–∏–ª–∫–∞ Python: {str(e)}"


def smart_column_mapping(uploaded_columns):
    mapping = {}
    used_standards = set()

    all_standard_options = []
    for standard_name, variations in STANDARD_COLUMNS.items():
        for var in variations:
            all_standard_options.append((var, standard_name))
    choices_dict = {opt[0]: opt[1] for opt in all_standard_options}
    choice_keys = list(choices_dict.keys())

    print(f"–í—Ö—ñ–¥–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ: {uploaded_columns}")
    for col in uploaded_columns:
        clean_col = str(col).lower().strip().replace('_', ' ')
        if not clean_col: continue

        best_match, score = process.extractOne(clean_col, choice_keys, scorer=fuzz.token_sort_ratio)

        if score > 60:
            standard_name = choices_dict[best_match]
            if standard_name not in used_standards:
                mapping[col] = standard_name
                used_standards.add(standard_name)
                print(f"–ó–Ω–∞–π–¥–µ–Ω–æ: '{col}' -> '{standard_name}' ({score}%)")
    return mapping


def generate_insights(df):
    insights = []
    try:
        # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —á–∏—Å–ª–æ–≤—ñ –ø–æ–ª—è
        cols_to_numeric = ['Price_Per_Unit', 'Quantity', 'Cost_Per_Unit']
        for col in cols_to_numeric:
            if col in df.columns:
                df[col] = pd.to_numeric(df[col], errors='coerce')

        df['Revenue'] = df['Price_Per_Unit'] * df['Quantity']

        # –Ü–º–ø'—é—Ç–∞—Ü—ñ—è
        if 'Cost_Per_Unit' in df.columns:
            nan_mask = df['Cost_Per_Unit'].isnull()
            nan_count = nan_mask.sum()

            if nan_count > 0:
                if nan_count == len(df):
                    # –ü–æ–≤–Ω—ñ—Å—Ç—é –≤—ñ–¥—Å—É—Ç–Ω—ñ–π
                    if 'Product_Category' in df.columns:
                        # –û–ø—Ç–∏–º—ñ–∑–∞—Ü—ñ—è: map –∑–∞–º—ñ—Å—Ç—å apply
                        unique_cats = df['Product_Category'].astype(str).unique()
                        cat_margin_map = {}
                        for cat in unique_cats:
                            smart_cat = get_smart_category(cat)
                            cat_margin_map[cat] = 1 - MARGIN_FALLBACKS_BY_CATEGORY.get(smart_cat, 0.30)

                        df.loc[nan_mask, 'Cost_Per_Unit'] = df.loc[nan_mask, 'Price_Per_Unit'] * df.loc[
                            nan_mask, 'Product_Category'].astype(str).map(cat_margin_map)
                        insights.append(f"‚ö†Ô∏è –°–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å –≤—ñ–¥—Å—É—Ç–Ω—è. –†–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∫–∞—Ç–µ–≥–æ—Ä—ñ–π.")
                    else:
                        df.loc[nan_mask, 'Cost_Per_Unit'] = df.loc[nan_mask, 'Price_Per_Unit'] * 0.7
                        insights.append(f"‚ö†Ô∏è –°–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å –≤—ñ–¥—Å—É—Ç–Ω—è. –ó–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –º–∞—Ä–∂—É 30%.")
                else:
                    # –ß–∞—Å—Ç–∫–æ–≤–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π
                    df.loc[nan_mask, 'Cost_Per_Unit'] = df.loc[nan_mask, 'Price_Per_Unit'] * 0.7
                    insights.append(f"‚ÑπÔ∏è –î–ª—è {nan_count} –∑–∞–ø–∏—Å—ñ–≤ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–æ –º–∞—Ä–∂—É 30%.")

                # 3. –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ Profit
            if 'Cost_Per_Unit' in df.columns:
                df['Profit'] = df['Revenue'] - (df['Quantity'] * df['Cost_Per_Unit'])
            else:
                df['Profit'] = float('nan')

                # 4. –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞
            df_cleaned = df.dropna(subset=['Revenue'])
            total_revenue = df_cleaned['Revenue'].sum()
            total_transactions = df_cleaned['Transaction_ID'].nunique()
            insights.append(f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ {total_transactions} —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π –Ω–∞ —Å—É–º—É {total_revenue:,.2f} –≥—Ä–Ω.")

            aov = 0
            if total_transactions > 0:
                aov = total_revenue / total_transactions
                insights.append(f"üìà –°–µ—Ä–µ–¥–Ω—ñ–π —á–µ–∫ (AOV): {aov:,.2f} –≥—Ä–Ω.")

            # –¢–æ–ø –∫–∞—Ç–µ–≥–æ—Ä—ñ—è (—Å–ø—Ä–æ—â–µ–Ω–æ –¥–ª—è —à–≤–∏–¥–∫–æ—Å—Ç—ñ)
            if 'Product_Category' in df_cleaned.columns:
                cat_group = df_cleaned.groupby('Product_Category')['Revenue'].sum().sort_values(ascending=False)
                if not cat_group.empty:
                    insights.append(f"üèÜ –¢–æ–ø-–∫–∞—Ç–µ–≥–æ—Ä—ñ—è: '{cat_group.idxmax()}' ({cat_group.max():,.2f} –≥—Ä–Ω).")

            if 'Client_Region' in df_cleaned.columns and df_cleaned['Client_Region'].notna().any():
                reg_group = df_cleaned.groupby('Client_Region')['Revenue'].sum().sort_values(ascending=False)
                if not reg_group.empty:
                    insights.append(f"üåç –¢–æ–ø-—Ä–µ–≥—ñ–æ–Ω: '{reg_group.idxmax()}' ({reg_group.max():,.2f} –≥—Ä–Ω).")

            if aov > 0:
                target_aov = aov * 1.15
                insights.append(f"üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –ü—ñ–¥–Ω—ñ–º—ñ—Ç—å —Å–µ—Ä–µ–¥–Ω—ñ–π —á–µ–∫ –¥–æ {target_aov:,.2f} –≥—Ä–Ω.")

        return insights

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {e}")
        return ["–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É –¥–∞–Ω–∏—Ö."]


@app.route('/api/upload', methods=['POST'])
def upload_file():
    gc.collect()  # –û—á–∏—â–∞—î–º–æ –ø–∞–º'—è—Ç—å –ø–µ—Ä–µ–¥ —Å—Ç–∞—Ä—Ç–æ–º

    if 'file' not in request.files: return jsonify({"error": "–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}), 400
    file = request.files['file']
    if file.filename == '': return jsonify({"error": "–§–∞–π–ª –Ω–µ –æ–±—Ä–∞–Ω–æ"}), 400

    if file and file.filename.endswith('.csv'):
        try:
            df = pd.read_csv(file)

            # –ú–∞–ø—ñ–Ω–≥
            column_mapping = smart_column_mapping(df.columns.tolist())
            df.rename(columns=column_mapping, inplace=True)

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
            all_keys = list(TABLEAU_SCHEMA.keys())
            # –°—Ç–≤–æ—Ä—é—î–º–æ DataFrame –æ–¥—Ä–∞–∑—É –∑ –ø–æ—Ç—Ä—ñ–±–Ω–∏–º–∏ –∫–æ–ª–æ–Ω–∫–∞–º–∏, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –ø—Ä–æ–±–ª–µ–º concat
            df_final = pd.DataFrame(index=df.index)

            for col in all_keys:
                if col in df.columns:
                    df_final[col] = df[col]
                else:
                    df_final[col] = None  # –°—Ç–≤–æ—Ä—é—î–º–æ –ø–æ—Ä–æ–∂–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏

            print("–ó–∞—Å—Ç–æ—Å–æ–≤—É—é —Ç–∏–ø–∏ –¥–∞–Ω–∏—Ö...")
            # –ö–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ –¥–∞—Ç–∏
            if 'Transaction_Date' in df_final.columns:
                df_final['Transaction_Date'] = pd.to_datetime(df_final['Transaction_Date'], errors='coerce')

            # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ç–∏–ø–∏ (Convert to string handled specifically)
            for col, dtype in TABLEAU_SCHEMA.items():
                if dtype == 'string' or dtype == 'object':
                    df_final[col] = df_final[col].astype('string')
                elif col != 'Transaction_Date':  # Skip date as it is already handled
                    df_final[col] = pd.to_numeric(df_final[col], errors='coerce')

            # –Ü–Ω—Å–∞–π—Ç–∏
            insights = generate_insights(df_final)

            # –ó–∞–ø–∏—Å —É —Ñ–∞–π–ª
            temp_file_path = 'temp.hyper'
            print(f"–ö–æ–Ω–≤–µ—Ä—Ç—É—é —É {temp_file_path}...")

            # –í–∏–¥–∞–ª—è—î–º–æ —Å—Ç–∞—Ä–∏–π —Ñ–∞–π–ª —è–∫—â–æ —î
            if os.path.exists(temp_file_path): os.remove(temp_file_path)

            # –ü—Ä–∏–º—É—Å–æ–≤–∞ –æ—á–∏—Å—Ç–∫–∞ –ø–∞–º'—è—Ç—ñ –ø–µ—Ä–µ–¥ –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—î—é
            del df
            gc.collect()

            pt.frame_to_hyper(df_final, temp_file_path, table='Extract')

            print("–ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –≤ Tableau...")
            tableau_error = publish_to_tableau_cloud(temp_file_path)

            if os.path.exists(temp_file_path): os.remove(temp_file_path)

            if tableau_error: insights.append(f"–ü–û–ú–ò–õ–ö–ê TABLEAU: {tableau_error}")

            return jsonify({"message": "–£—Å–ø—ñ—Ö!", "insights": insights}), 200

        except Exception as e:
            return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞: {str(e)}"}), 500
    return jsonify({"error": "–¢—ñ–ª—å–∫–∏ .csv"}), 400


if __name__ == '__main__':
    app.run()