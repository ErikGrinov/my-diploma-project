import os
import pandas as pd
from flask import Flask, request, jsonify
from flask_cors import CORS
from fuzzywuzzy import fuzz, process
import tableauserverclient as TSC
import pantab as pt
from tableauhyperapi import TableName

# --- –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –°–µ—Ä–≤–µ—Ä–∞ ---
app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "https://my-diploma-project.vercel.app"}})

# --- –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞ –ú–æ–¥–µ–ª—å –î–∞–Ω–∏—Ö ---
STANDARD_COLUMNS = {
    'Transaction_Date': ['–¥–∞—Ç–∞', '–¥–∞—Ç–∞ –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è', 'date', 'order_date'],
    'Transaction_ID': ['id', '–Ω–æ–º–µ—Ä –∑–∞–º–æ–≤–ª–µ–Ω–Ω—è', 'transaction id', 'order id', '–Ω–æ–º–µ—Ä —á–µ–∫–∞'],
    'Product_Category': ['–∫–∞—Ç–µ–≥–æ—Ä—ñ—è', 'category', 'product category', '–∫–∞—Ç–µ–≥–æ—Ä—ñ—è —Ç–æ–≤–∞—Ä—É'],
    'Quantity': ['–∫—ñ–ª—å–∫—ñ—Å—Ç—å', 'quantity', 'qty', '–∫—ñ–ª-—Ç—å'],
    'Price_Per_Unit': ['—Ü—ñ–Ω–∞', 'price', '—Ü—ñ–Ω–∞ –∑–∞ –æ–¥'],
    'Cost_Per_Unit': ['—Å–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å', 'cost', 'cost per unit'],
    'Client_Region': ['—Ä–µ–≥—ñ–æ–Ω', '–º—ñ—Å—Ç–æ', 'region', 'city', 'client region', '—Ä–µ–≥—ñ–æ–Ω –¥–æ—Å—Ç–∞–≤–∫–∏'],
}

# --- –°–•–ï–ú–ê –î–ê–ù–ò–• (–ë–ï–ó Profit/Revenue) ---
TABLEAU_SCHEMA = {
    'Transaction_Date': 'datetime64[ns]',
    'Transaction_ID': 'object',
    'Product_Category': 'object',
    'Quantity': 'Int64',
    'Price_Per_Unit': 'float64',
    'Cost_Per_Unit': 'float64',
    'Client_Region': 'object'
}

# --- "–†–û–ó–£–ú–ù–ò–ô" –°–õ–û–í–ù–ò–ö –ú–ê–†–ñ–Ü (–ë–µ–∑ –∑–º—ñ–Ω) ---
MARGIN_FALLBACKS_BY_CATEGORY = {
    'Electronics': 0.20,
    'Apparel': 0.40,
    'Home Goods': 0.35,
    'Food': 0.15,
    'Automotive': 0.10,
    '–ï–ª–µ–∫—Ç—Ä–æ–Ω—ñ–∫–∞': 0.20,
    '–û–¥—è–≥': 0.40,
    '–¢–æ–≤–∞—Ä–∏ –¥–ª—è –¥–æ–º—É': 0.35,
    '–ü—Ä–æ–¥—É–∫—Ç–∏': 0.15,
    'default': 0.30
}

# --- "–†–û–ó–£–ú–ù–ê" –§–£–ù–ö–¶–Ü–Ø –î–õ–Ø –ö–ê–¢–ï–ì–û–†–Ü–ô (–ë–µ–∑ –∑–º—ñ–Ω) ---
CLEAN_CATEGORIES = list(MARGIN_FALLBACKS_BY_CATEGORY.keys())


def get_smart_category(dirty_category):
    if not isinstance(dirty_category, str):
        return 'default'
    best_match, score = process.extractOne(dirty_category.lower(), CLEAN_CATEGORIES, scorer=fuzz.token_set_ratio)
    if score > 60:
        return best_match
    else:
        return 'default'


# --- –§—É–Ω–∫—Ü—ñ—è –ü—É–±–ª—ñ–∫–∞—Ü—ñ—ó (–ë–µ–∑ –∑–º—ñ–Ω) ---
def publish_to_tableau_cloud(file_path):
    try:
        server_url = os.environ['TABLEAU_SERVER_URL']
        site_id = os.environ['TABLEAU_SITE_ID']
        pat_name = os.environ['TABLEAU_PAT_NAME']
        pat_secret = os.environ['TABLEAU_PAT_SECRET']
        datasource_name_to_update = 'live_sales_data'
        print(f"–ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ {server_url} –Ω–∞ —Å–∞–π—Ç—ñ {site_id}...")
        tableau_auth = TSC.PersonalAccessTokenAuth(pat_name, pat_secret, site_id=site_id)
        server = TSC.Server(server_url, use_server_version=True)
        with server.auth.sign_in(tableau_auth):
            print("–£—Å–ø—ñ—à–Ω–∏–π –≤—Ö—ñ–¥ –≤ Tableau Cloud.")
            req_option = TSC.RequestOptions()
            req_option.filter.add(TSC.Filter(TSC.RequestOptions.Field.Name,
                                             TSC.RequestOptions.Operator.Equals,
                                             datasource_name_to_update))
            all_datasources, _ = server.datasources.get(req_option)
            if not all_datasources:
                error_msg = f"–ü–æ–º–∏–ª–∫–∞: –î–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö –∑ —ñ–º'—è–º '{datasource_name_to_update}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ."
                print(f"!! {error_msg}")
                return error_msg
            datasource_to_update = all_datasources[0]
            print(f"–î–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö –∑–Ω–∞–π–¥–µ–Ω–æ (ID: {datasource_to_update.id}). –ü—É–±–ª—ñ–∫—É—é –Ω–æ–≤—É –≤–µ—Ä—Å—ñ—é...")
            updated_datasource = server.datasources.publish(datasource_to_update, file_path, 'Overwrite')
            print(f"–î–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö '{updated_datasource.name}' —É—Å–ø—ñ—à–Ω–æ –æ–Ω–æ–≤–ª–µ–Ω–æ.")
            # --- ‚Üì‚Üì‚Üì –ü–†–ò–ú–£–°–û–í–ï –û–ù–û–í–õ–ï–ù–ù–Ø (REFRESH) ‚Üì‚Üì‚Üì ---
            print("–ó–∞–ø—É—Å–∫–∞—é –ø—Ä–∏–º—É—Å–æ–≤–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è (refresh) –¥–∂–µ—Ä–µ–ª–∞...")
            try:
                server.datasources.refresh(datasource_to_update)
                print("–ü—Ä–∏–º—É—Å–æ–≤–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è (refresh) —É—Å–ø—ñ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω–æ.")
            except Exception as e:
                print(f"!! –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥ —á–∞—Å –∑–∞–ø—É—Å–∫—É 'refresh', –∞–ª–µ —Ü–µ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ: {e}")
            return None
    except TSC.ServerResponseError as e:
        error_msg = f"–ü–æ–º–∏–ª–∫–∞ Tableau API: {e.summary} - {e.detail}"
        print(f"!! {error_msg}")
        return error_msg
    except Exception as e:
        error_msg = f"–ö—Ä–∏—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞ Python: {str(e)}"
        print(f"!! {error_msg}")
        return error_msg


# --- –§—É–Ω–∫—Ü—ñ—è –ú–∞–ø—ñ–Ω–≥—É (–ë–µ–∑ –∑–º—ñ–Ω) ---
def smart_column_mapping(uploaded_columns):
    mapping = {}
    all_standard_options = []
    for standard_name, variations in STANDARD_COLUMNS.items():
        for var in variations:
            all_standard_options.append((var, standard_name))
    choices_dict = {opt[0]: opt[1] for opt in all_standard_options}
    choice_keys = list(choices_dict.keys())
    print(f"–í—Ö—ñ–¥–Ω—ñ —Å—Ç–æ–≤–ø—Ü—ñ: {uploaded_columns}")
    for col in uploaded_columns:
        clean_col = col.lower().strip().replace('_', ' ')
        best_match, score = process.extractOne(clean_col, choice_keys, scorer=fuzz.token_sort_ratio)
        if score > 60:
            standard_name = choices_dict[best_match]
            mapping[col] = standard_name
            print(f"–ó–Ω–∞–π–¥–µ–Ω–æ: '{col}' -> '{standard_name}' (–°—Ö–æ–∂—ñ—Å—Ç—å: {score}%)")
        else:
            print(f"–ù–ï –∑–Ω–∞–π–¥–µ–Ω–æ: '{col}' (–ù–∞–π–∫—Ä–∞—â–∏–π –≤–∞—Ä—ñ–∞–Ω—Ç: '{best_match}' –∑ {score}%)")
    return mapping


# --- –§–£–ù–ö–¶–Ü–Ø –Ü–ù–°–ê–ô–¢–Ü–í (–Ø–∫–∞ –ù–ï —Ä–æ–∑—Ä–∞—Ö–æ–≤—É—î Profit/Revenue —Å–∞–º–æ—Å—Ç—ñ–π–Ω–æ) ---
def generate_insights(df):
    insights = []
    try:
        # --- 1. –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–∏—Ö ---
        df['Price_Per_Unit'] = pd.to_numeric(df['Price_Per_Unit'], errors='coerce')
        df['Quantity'] = pd.to_numeric(df['Quantity'], errors='coerce')
        if 'Cost_Per_Unit' in df.columns:
            df['Cost_Per_Unit'] = pd.to_numeric(df['Cost_Per_Unit'], errors='coerce')

        # --- 2. –†–û–ó–£–ú–ù–ê –Ü–ú–ü'–Æ–¢–ê–¶–Ü–Ø –°–û–ë–Ü–í–ê–†–¢–û–°–¢–Ü ---
        # (–¶–µ–π –±–ª–æ–∫ –ø–æ—Ç—Ä—ñ–±–µ–Ω, —â–æ–± –ó–ê–ü–û–í–ù–ò–¢–ò Cost_Per_Unit, —è–∫—â–æ –≤—ñ–Ω –ø–æ—Ä–æ–∂–Ω—ñ–π)
        if 'Cost_Per_Unit' in df.columns:
            nan_count = df['Cost_Per_Unit'].isnull().sum()
            total_count = len(df)
            if nan_count == total_count:
                if 'Product_Category' not in df.columns:
                    fallback_margin = MARGIN_FALLBACKS_BY_CATEGORY['default']
                    df['Cost_Per_Unit'].fillna(df['Price_Per_Unit'] * (1 - fallback_margin), inplace=True)
                    insights.append(
                        f"‚ö†Ô∏è **–£–≤–∞–≥–∞:** –°–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å (`Cost_Per_Unit`) –¢–ê –ö–∞—Ç–µ–≥–æ—Ä—ñ—ó (`Product_Category`) –≤—ñ–¥—Å—É—Ç–Ω—ñ. –î–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –ø—Ä–∏–±—É—Ç–∫—É –±—É–ª–∞ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–∞ **–∑–∞–≥–∞–ª—å–Ω–∞ —Ç–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ –º–∞—Ä–∂–∞ —É {fallback_margin:.0%}**.")
                else:
                    print("–Ü–º–ø'—é—Ç–∞—Ü—ñ—è: Cost_Per_Unit –ø–æ–≤–Ω—ñ—Å—Ç—é –≤—ñ–¥—Å—É—Ç–Ω—ñ–π. –ó–∞—Å—Ç–æ—Å–æ–≤—É—é '—Ä–æ–∑—É–º–Ω—É' –º–∞—Ä–∂—É –∑–∞ –∫–∞—Ç–µ–≥–æ—Ä—ñ—è–º–∏...")
                    df['Cost_Per_Unit'] = df.apply(
                        lambda row: row['Price_Per_Unit'] * (
                                    1 - MARGIN_FALLBACKS_BY_CATEGORY[get_smart_category(row['Product_Category'])]),
                        axis=1
                    )
                    insights.append(
                        f"‚ö†Ô∏è **–£–≤–∞–≥–∞:** –°–æ–±—ñ–≤–∞—Ä—Ç—ñ—Å—Ç—å (`Cost_Per_Unit`) –±—É–ª–∞ –≤—ñ–¥—Å—É—Ç–Ω—è. –ü—Ä–∏–±—É—Ç–æ–∫ —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–æ **–Ω–∞ –æ—Å–Ω–æ–≤—ñ '—Ä–æ–∑—É–º–Ω–æ–≥–æ' –∑—ñ—Å—Ç–∞–≤–ª–µ–Ω–Ω—è –∫–∞—Ç–µ–≥–æ—Ä—ñ–π** (–Ω–∞–ø—Ä., 'gadgets' -> 'Electronics').")
            elif nan_count > 0:
                print("–Ü–º–ø'—é—Ç–∞—Ü—ñ—è: Cost_Per_Unit —á–∞—Å—Ç–∫–æ–≤–æ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π. –†–æ–∑—Ä–∞—Ö–æ–≤—É—é —Å–µ—Ä–µ–¥–Ω—é –º–∞—Ä–∂—É...")
                good_data = df.dropna(subset=['Cost_Per_Unit', 'Price_Per_Unit'])
                avg_margin_ratio = (good_data['Price_Per_Unit'] - good_data['Cost_Per_Unit']).sum() / good_data[
                    'Price_Per_Unit'].sum()
                if avg_margin_ratio > 0 and avg_margin_ratio < 1:
                    avg_cost_ratio = 1 - avg_margin_ratio
                    df['Cost_Per_Unit'].fillna(df['Price_Per_Unit'] * avg_cost_ratio, inplace=True)
                    insights.append(
                        f"‚ÑπÔ∏è **–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è:** {nan_count} —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π –Ω–µ –º–∞–ª–∏ —Å–æ–±—ñ–≤–∞—Ä—Ç–æ—Å—Ç—ñ. –î–æ –Ω–∏—Ö –±—É–ª–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–∞ **—Å–µ—Ä–µ–¥–Ω—è —Ä–æ–∑—Ä–∞—Ö–æ–≤–∞–Ω–∞ –º–∞—Ä–∂–∞ ({avg_margin_ratio:.1%})** –∑ —Ü—å–æ–≥–æ —Ñ–∞–π–ª—É.")
                else:
                    df['Cost_Per_Unit'].fillna(df['Price_Per_Unit'] * (1 - 0.30), inplace=True)
                    insights.append(
                        f"‚ö†Ô∏è **–£–≤–∞–≥–∞:** –ù–µ –≤–¥–∞–ª–æ—Å—è —Ä–æ–∑—Ä–∞—Ö—É–≤–∞—Ç–∏ —Å–µ—Ä–µ–¥–Ω—é –º–∞—Ä–∂—É. –î–ª—è {nan_count} —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π –±—É–ª–∞ –∑–∞—Å—Ç–æ—Å–æ–≤–∞–Ω–∞ **—Ç–µ–æ—Ä–µ—Ç–∏—á–Ω–∞ –º–∞—Ä–∂–∞ —É 30%**.")

        # --- 3. –ü—Ä–æ–¥–æ–≤–∂—É—î–º–æ –ê–Ω–∞–ª—ñ–∑ (–ë–ï–ó —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É Profit/Revenue) ---
        # (–ú–∏ —Ä–æ–∑—Ä–∞—Ö—É—î–º–æ —ó—Ö —É Tableau)

        # –†–æ–∑—Ä–∞—Ö—É—î–º–æ Revenue —Ç–∏–º—á–∞—Å–æ–≤–æ –õ–ò–®–ï –¥–ª—è —ñ–Ω—Å–∞–π—Ç—ñ–≤
        df_temp_revenue = (df['Price_Per_Unit'] * df['Quantity'])
        total_revenue = df_temp_revenue.sum()
        total_transactions = df['Transaction_ID'].nunique()
        insights.append(
            f"‚úÖ –ü—Ä–æ–∞–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω–æ {total_transactions} —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü—ñ–π –Ω–∞ –∑–∞–≥–∞–ª—å–Ω—É —Å—É–º—É {total_revenue:,.2f} –≥—Ä–Ω.")

        aov = 0
        if total_transactions > 0:
            aov = total_revenue / total_transactions
            insights.append(f"üìà –°–µ—Ä–µ–¥–Ω—ñ–π —á–µ–∫ (AOV) —É —Ü—å–æ–º—É –Ω–∞–±–æ—Ä—ñ –¥–∞–Ω–∏—Ö —Å—Ç–∞–Ω–æ–≤–∏—Ç—å {aov:,.2f} –≥—Ä–Ω.")

        if 'Product_Category' in df.columns:
            df['Temp_Revenue'] = df_temp_revenue  # –î–æ–¥–∞—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤—É –≤–∏—Ä—É—á–∫—É
            df['Clean_Category'] = df['Product_Category'].apply(get_smart_category)
            category_group = df.groupby('Clean_Category')['Temp_Revenue'].sum().sort_values(ascending=False)
            top_category_name = category_group.idxmax()
            top_category_revenue = category_group.max()
            insights.append(f"üèÜ –¢–æ–ø-–∫–∞—Ç–µ–≥–æ—Ä—ñ—è: '{top_category_name}' –∑ –≤–∏—Ä—É—á–∫–æ—é {top_category_revenue:,.2f} –≥—Ä–Ω.")

        if 'Client_Region' in df.columns:
            region_group = df.groupby('Client_Region')['Temp_Revenue'].sum().sort_values(ascending=False)
            top_region_name = region_group.idxmax()
            top_region_revenue = region_group.max()
            insights.append(f"üåç –¢–æ–ø-—Ä–µ–≥—ñ–æ–Ω: '{top_region_name}' –∑ –≤–∏—Ä—É—á–∫–æ—é {top_region_revenue:,.2f} –≥—Ä–Ω.")

        if aov > 0:
            target_aov = aov * 1.15
            insights.append(
                f"üí° **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –í–∞—à —Å–µ—Ä–µ–¥–Ω—ñ–π —á–µ–∫ {aov:,.2f} –≥—Ä–Ω. –°–ø—Ä–æ–±—É–π—Ç–µ –≤–ø—Ä–æ–≤–∞–¥–∏—Ç–∏ –ø–æ—Ä—ñ–≥ –±–µ–∑–∫–æ—à—Ç–æ–≤–Ω–æ—ó –¥–æ—Å—Ç–∞–≤–∫–∏...")

        if 'Product_Category' in df.columns and len(category_group) > 1:
            bottom_category_name = category_group.idxmin()
            bottom_category_revenue = category_group.min()
            insights.append(
                f"üìâ **–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—è:** –ö–∞—Ç–µ–≥–æ—Ä—ñ—è '{bottom_category_name}' –ø—Ä–∏–Ω–æ—Å–∏—Ç—å –Ω–∞–π–º–µ–Ω—à–µ –¥–æ—Ö–æ–¥—É ({bottom_category_revenue:,.2f} –≥—Ä–Ω)...")

        return insights

    except Exception as e:
        print(f"–ü–æ–º–∏–ª–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —ñ–Ω—Å–∞–π—Ç—ñ–≤: {e}")
        return [f"–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–≥–µ–Ω–µ—Ä—É–≤–∞—Ç–∏ —ñ–Ω—Å–∞–π—Ç–∏: {e}"]


# --- –ì–û–õ–û–í–ù–ò–ô API ENDPOINT (–û–°–¢–ê–¢–û–ß–ù–ê –í–ï–†–°–Ü–Ø) ---
@app.route('/api/upload', methods=['POST'])
def upload_file():
    if 'file' not in request.files:
        return jsonify({"error": "–§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ"}), 400
    file = request.files['file']
    if file.filename == '':
        return jsonify({"error": "–§–∞–π–ª –Ω–µ –æ–±—Ä–∞–Ω–æ"}), 400

    if file and file.filename.endswith('.csv'):
        try:
            df = pd.read_csv(file)
            column_mapping = smart_column_mapping(df.columns.tolist())
            df.rename(columns=column_mapping, inplace=True)

            # 1. –ì–∞—Ä–∞–Ω—Ç—É—î–º–æ, —â–æ –í–°–Ü —Å—Ç–æ–≤–ø—Ü—ñ —ñ—Å–Ω—É—é—Ç—å
            all_standard_keys = list(STANDARD_COLUMNS.keys())
            df_standard = pd.DataFrame(columns=all_standard_keys)
            final_columns = [col for col in all_standard_keys if col in df.columns]
            df_final = pd.concat([df_standard, df[final_columns]], sort=False)

            # 2. –ü–†–ò–ú–£–°–û–í–ï –ó–ê–°–¢–û–°–£–í–ê–ù–ù–Ø –¢–ò–ü–Ü–í –î–ê–ù–ò–• (–í–∏–ø—Ä–∞–≤–ª—è—î "Arrow type: na")
            print("–ü—Ä–∏–º—É—Å–æ–≤–æ –∑–∞—Å—Ç–æ—Å–æ–≤—É—é —Ç–∏–ø–∏ –¥–∞–Ω–∏—Ö...")
            try:
                if 'Transaction_Date' in df_final.columns:
                    df_final['Transaction_Date'] = pd.to_datetime(df_final['Transaction_Date'], errors='coerce')
                df_final = df_final.astype(TABLEAU_SCHEMA, errors='ignore')
            except Exception as e:
                print(f"!! –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞—Å—Ç–æ—Å—É–≤–∞–Ω–Ω—ñ —Å—Ö–µ–º–∏ .astype(): {e}")

            # 3. –ì–µ–Ω–µ—Ä—É—î–º–æ —ñ–Ω—Å–∞–π—Ç–∏ –¢–ê –ó–ê–ü–û–í–ù–Æ–Ñ–ú–û 'Cost_Per_Unit'
            insights = generate_insights(df_final)

            # 4. –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ñ–∞–π–ª –¢–ò–ú–ß–ê–°–û–í–û —É .hyper —Ñ–æ—Ä–º–∞—Ç—ñ
            temp_file_path = os.path.join('temp_cleaned_data.hyper')
            print(f"–ö–æ–Ω–≤–µ—Ä—Ç—É—é –¥–∞–Ω—ñ —É {temp_file_path}...")

            # –í–ê–ñ–õ–ò–í–û: –ú–∏ –ø–µ—Ä–µ–¥–∞—î–º–æ df_final (—è–∫–∏–π —Ç–µ–ø–µ—Ä –º–∞—î –ó–ê–ü–û–í–ù–ï–ù–ò–ô Cost_Per_Unit)
            pt.frame_to_hyper(df_final, temp_file_path, table='Extract')

            # 5. –í–∏–∫–ª–∏–∫–∞—î–º–æ –Ω–∞—à—É —Ñ—É–Ω–∫—Ü—ñ—é –¥–ª—è –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –≤ —Ö–º–∞—Ä—É
            print("–ó–∞–ø—É—Å–∫–∞—é –æ–Ω–æ–≤–ª–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö –≤ Tableau Cloud...")
            tableau_error = publish_to_tableau_cloud(temp_file_path)

            # 6. –í–∏–¥–∞–ª—è—î–º–æ —Ç–∏–º—á–∞—Å–æ–≤–∏–π —Ñ–∞–π–ª
            os.remove(temp_file_path)

            # 7. –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –ø–æ–º–∏–ª–∫–∞
            if tableau_error:
                insights.append(f"–ü–û–ú–ò–õ–ö–ê TABLEAU: {tableau_error}")

            # 8. –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ —ñ–Ω—Å–∞–π—Ç–∏
            return jsonify({
                "message": "–§–∞–π–ª —É—Å–ø—ñ—à–Ω–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ —Ç–∞ –≤—ñ–¥–ø—Ä–∞–≤–ª–µ–Ω–æ –≤ Tableau Cloud!",
                "insights": insights
            }), 200

        except Exception as e:
            return jsonify({"error": f"–ü–æ–º–∏–ª–∫–∞ –æ–±—Ä–æ–±–∫–∏ —Ñ–∞–π–ª—É: {str(e)}"}), 500
    else:
        return jsonify({"error": "–ù–µ–≤—ñ—Ä–Ω–∏–π —Ç–∏–ø —Ñ–∞–π–ª—É. –ü–æ—Ç—Ä—ñ–±–µ–Ω .csv"}), 400


# --- –ó–∞–ø—É—Å–∫ —Å–µ—Ä–≤–µ—Ä–∞ ---
if __name__ == '__main__':
    app.run()